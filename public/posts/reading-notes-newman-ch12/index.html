<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Reading Notes: Newman&#39;s Networks Chapter 12 - Network Inference | Notes on AI4Science &amp; Graph Theory</title>
<meta name="keywords" content="reading-notes, network-theory, network-inference, statistical-inference, network-reconstruction">
<meta name="description" content="Study notes for Chapter 12 of Newman&#39;s &#39;Networks: An Introduction&#39; covering statistical inference, network reconstruction, and missing data imputation">
<meta name="author" content="Linlin-resh">
<link rel="canonical" href="https://Linlin-resh.github.io/posts/reading-notes-newman-ch12/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.36819bea596090d8b48cf10d9831382996197aa7e4fc86f792f7c08c9ca4d23b.css" integrity="sha256-NoGb6llgkNi0jPENmDE4KZYZeqfk/Ib3kvfAjJyk0js=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://Linlin-resh.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://Linlin-resh.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://Linlin-resh.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://Linlin-resh.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://Linlin-resh.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://Linlin-resh.github.io/posts/reading-notes-newman-ch12/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><link rel="stylesheet" href="https://Linlin-resh.github.io/css/math-enhancement.css"><script>
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$', '$$'], ['\\[', '\\]']],
      processEscapes: true,
      processEnvironments: true,
      packages: {'[+]': ['ams', 'newcommand', 'configmacros']}
    },
    options: {
      skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
      ignoreHtmlClass: 'tex2jax_ignore',
      processHtmlClass: 'tex2jax_process'
    },
    loader: {
      load: ['[tex]/ams', '[tex]/newcommand', '[tex]/configmacros']
    }
  };
</script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script defer id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Source+Code+Pro:wght@300;400;500;600;700&family=Source+Serif+Pro:wght@300;400;500;600;700&display=swap" rel="stylesheet">
<meta property="og:url" content="https://Linlin-resh.github.io/posts/reading-notes-newman-ch12/">
  <meta property="og:site_name" content="Notes on AI4Science & Graph Theory">
  <meta property="og:title" content="Reading Notes: Newman&#39;s Networks Chapter 12 - Network Inference">
  <meta property="og:description" content="Study notes for Chapter 12 of Newman&#39;s &#39;Networks: An Introduction&#39; covering statistical inference, network reconstruction, and missing data imputation">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-08-29T00:00:00+00:00">
    <meta property="article:modified_time" content="2025-08-29T00:00:00+00:00">
    <meta property="article:tag" content="Reading-Notes">
    <meta property="article:tag" content="Network-Theory">
    <meta property="article:tag" content="Network-Inference">
    <meta property="article:tag" content="Statistical-Inference">
    <meta property="article:tag" content="Network-Reconstruction">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Reading Notes: Newman&#39;s Networks Chapter 12 - Network Inference">
<meta name="twitter:description" content="Study notes for Chapter 12 of Newman&#39;s &#39;Networks: An Introduction&#39; covering statistical inference, network reconstruction, and missing data imputation">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://Linlin-resh.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Reading Notes: Newman's Networks Chapter 12 - Network Inference",
      "item": "https://Linlin-resh.github.io/posts/reading-notes-newman-ch12/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Reading Notes: Newman's Networks Chapter 12 - Network Inference",
  "name": "Reading Notes: Newman\u0027s Networks Chapter 12 - Network Inference",
  "description": "Study notes for Chapter 12 of Newman's 'Networks: An Introduction' covering statistical inference, network reconstruction, and missing data imputation",
  "keywords": [
    "reading-notes", "network-theory", "network-inference", "statistical-inference", "network-reconstruction"
  ],
  "articleBody": "Introduction Chapter 12 of Newman’s Networks: An Introduction explores network inference - the process of reconstructing or inferring network structure from partial or noisy data. This chapter covers statistical methods, machine learning approaches, and practical techniques for network reconstruction.\n12.1 Statistical Inference Maximum Likelihood Estimation Likelihood Function Likelihood function: $$L(\\theta) = \\prod_{i,j} P(A_{ij}|\\theta)$$\nWhere:\n$A_{ij}$: Observed adjacency matrix $\\theta$: Model parameters $P(A_{ij}|\\theta)$: Probability of edge $(i,j)$ given parameters Log-Likelihood Log-likelihood: $$\\ell(\\theta) = \\sum_{i,j} \\log P(A_{ij}|\\theta)$$\nMLE solution: $$\\hat{\\theta} = \\arg\\max_{\\theta} \\ell(\\theta)$$\nGradient Descent Gradient: $$\\frac{\\partial \\ell}{\\partial \\theta} = \\sum_{i,j} \\frac{1}{P(A_{ij}|\\theta)} \\frac{\\partial P(A_{ij}|\\theta)}{\\partial \\theta}$$\nUpdate rule: $$\\theta^{(t+1)} = \\theta^{(t)} + \\alpha \\frac{\\partial \\ell}{\\partial \\theta}$$\nBayesian Inference Prior Distribution Prior distribution: $$P(\\theta) = \\text{prior knowledge about parameters}$$\nCommon priors:\nUniform: $P(\\theta) = \\text{constant}$ Gaussian: $P(\\theta) = \\mathcal{N}(\\mu, \\sigma^2)$ Beta: $P(\\theta) = \\text{Beta}(\\alpha, \\beta)$ Posterior Distribution Posterior distribution: $$P(\\theta|A) = \\frac{P(A|\\theta)P(\\theta)}{P(A)}$$\nWhere $P(A)$ is the marginal likelihood: $$P(A) = \\int P(A|\\theta)P(\\theta) , d\\theta$$\nMarkov Chain Monte Carlo Metropolis-Hastings algorithm:\nPropose new parameter $\\theta’$ from proposal distribution $q(\\theta’|\\theta)$ Accept with probability: $$P_{\\text{accept}} = \\min\\left(1, \\frac{P(\\theta’|A)q(\\theta|\\theta’)}{P(\\theta|A)q(\\theta’|\\theta)}\\right)$$ Repeat until convergence Model Selection Information Criteria Akaike Information Criterion (AIC): $$AIC = -2\\ell(\\hat{\\theta}) + 2k$$\nBayesian Information Criterion (BIC): $$BIC = -2\\ell(\\hat{\\theta}) + k \\log n$$\nWhere $k$ is the number of parameters.\nCross-Validation k-fold cross-validation:\nSplit data into $k$ folds Train on $k-1$ folds, test on remaining fold Repeat for all folds Average performance 12.2 Network Reconstruction Link Prediction Similarity Measures Common neighbors: $$S_{ij} = |\\mathcal{N}_i \\cap \\mathcal{N}_j|$$\nJaccard coefficient: $$S_{ij} = \\frac{|\\mathcal{N}_i \\cap \\mathcal{N}_j|}{|\\mathcal{N}_i \\cup \\mathcal{N}_j|}$$\nAdamic-Adar: $$S_{ij} = \\sum_{k \\in \\mathcal{N}_i \\cap \\mathcal{N}_j} \\frac{1}{\\log k_k}$$\nPreferential attachment: $$S_{ij} = k_i \\cdot k_j$$\nResource allocation: $$S_{ij} = \\sum_{k \\in \\mathcal{N}_i \\cap \\mathcal{N}_j} \\frac{1}{k_k}$$\nPrediction Accuracy Area Under Curve (AUC): $$AUC = \\frac{1}{n(n-1)} \\sum_{i \\neq j} \\mathbb{I}(S_{ij} \u003e S_{\\text{random}})$$\nPrecision: $$P = \\frac{TP}{TP + FP}$$\nRecall: $$R = \\frac{TP}{TP + FN}$$\nF1-score: $$F1 = \\frac{2PR}{P + R}$$\nMatrix Completion Nuclear Norm Minimization Problem: $$\\min_{X} ||X - A||F^2 + \\lambda ||X||*$$\nWhere:\n$||X||_*$: Nuclear norm (sum of singular values) $\\lambda$: Regularization parameter Alternating Least Squares Algorithm:\nInitialize $U$ and $V$ randomly Fix $V$, solve for $U$: $U = \\arg\\min_U ||UV^T - A||_F^2$ Fix $U$, solve for $V$: $V = \\arg\\min_V ||UV^T - A||_F^2$ Repeat until convergence Solution: $X = UV^T$\nGraph Neural Networks Graph Convolutional Networks Layer update: $$H^{(l+1)} = \\sigma(\\tilde{A} H^{(l)} W^{(l)})$$\nWhere:\n$\\tilde{A} = D^{-1/2} A D^{-1/2}$: Normalized adjacency matrix $H^{(l)}$: Node features at layer $l$ $W^{(l)}$: Weight matrix at layer $l$ Link Prediction with GNNs Node embeddings: $$z_i = \\text{GNN}(A, X)_i$$\nLink prediction: $$P(A_{ij} = 1) = \\sigma(z_i^T z_j)$$\n12.3 Missing Data Imputation Missing Data Types Missing Completely at Random (MCAR) Definition: Missingness is independent of observed and unobserved data\nMathematical condition: $$P(M|X, Y) = P(M)$$\nWhere $M$ is the missingness indicator.\nMissing at Random (MAR) Definition: Missingness depends only on observed data\nMathematical condition: $$P(M|X, Y) = P(M|X)$$\nMissing Not at Random (MNAR) Definition: Missingness depends on unobserved data\nMathematical condition: $$P(M|X, Y) \\neq P(M|X)$$\nImputation Methods Mean Imputation Method: Replace missing values with mean of observed values\nFormula: $$\\hat{x}{ij} = \\frac{1}{n_j} \\sum{i: x_{ij} \\text{ observed}} x_{ij}$$\nAdvantages: Simple, fast Disadvantages: Reduces variance, may bias estimates\nRegression Imputation Method: Use regression to predict missing values\nFormula: $$\\hat{x}{ij} = \\beta_0 + \\sum{k \\neq j} \\beta_k x_{ik}$$\nAdvantages: Preserves relationships Disadvantages: Assumes linear relationships\nMultiple Imputation Method: Generate multiple imputed datasets\nAlgorithm:\nGenerate $m$ imputed datasets Analyze each dataset separately Combine results using Rubin’s rules Combined estimate: $$\\bar{\\theta} = \\frac{1}{m} \\sum_{i=1}^m \\hat{\\theta}_i$$\nVariance: $$\\text{Var}(\\bar{\\theta}) = \\frac{1}{m} \\sum_{i=1}^m \\text{Var}(\\hat{\\theta}i) + \\frac{1}{m-1} \\sum{i=1}^m (\\hat{\\theta}_i - \\bar{\\theta})^2$$\n12.4 Network Tomography Network Discovery Traceroute Method: Send packets with increasing TTL values\nInformation obtained:\nPath from source to destination Round-trip time Packet loss rate Limitations:\nMay not discover all paths Load balancing can cause inconsistencies Ping Method: Send ICMP echo requests\nInformation obtained:\nRound-trip time Packet loss rate Network reachability Limitations:\nOnly end-to-end information May be blocked by firewalls Topology Inference Graph Construction From traceroute data:\nCollect paths from multiple sources to multiple destinations Construct graph by connecting consecutive nodes in paths Merge duplicate edges From ping data:\nTest connectivity between all pairs of nodes Add edge if nodes can communicate May miss intermediate nodes Validation Consistency checks:\nTriangle inequality: $d_{ij} \\leq d_{ik} + d_{kj}$ Symmetry: $d_{ij} = d_{ji}$ Transitivity: If $A_{ik} = 1$ and $A_{kj} = 1$, then $A_{ij} = 1$ Statistical validation:\nCompare inferred topology with known topology Use cross-validation techniques 12.5 Applications to Materials Science Defect Network Inference Problem Given: Partial observations of defect interactions Goal: Infer complete defect network structure\nMathematical formulation: $$\\min_{A} ||A - A_{\\text{observed}}||_F^2 + \\lambda R(A)$$\nWhere $R(A)$ is a regularization term.\nMethods Sparse reconstruction: $$R(A) = ||A||_1$$\nLow-rank reconstruction: $$R(A) = ||A||_*$$\nCommunity structure: $$R(A) = \\sum_{c} ||A_c||_F^2$$\nNanowire Network Reconstruction Problem Given: Partial electrical measurements Goal: Infer complete nanowire network\nConstraints:\nElectrical: Ohm’s law must be satisfied Topological: Network must be connected Physical: Edge weights must be positive Optimization Objective function: $$\\min_{A, R} \\sum_{i,j} (V_i - V_j - R_{ij} I_{ij})^2 + \\lambda ||A||_1$$\nConstraints:\n$A_{ij} \\geq 0$ (positive resistance) $A_{ij} = 0$ if no nanowire between $i$ and $j$ $\\sum_j A_{ij} \u003e 0$ (each node must have at least one connection) Phase Transition Inference Problem Given: Partial observations of phase transitions Goal: Infer complete phase diagram\nNetwork representation:\nNodes: Different phases Edges: Phase transitions Weights: Transition probabilities Methods Bayesian inference: $$P(\\text{phase}|T, P) = \\frac{P(T, P|\\text{phase})P(\\text{phase})}{P(T, P)}$$\nMachine learning: $$f: (T, P) \\rightarrow \\text{phase}$$\nCode Example: Network Inference import networkx as nx import numpy as np import matplotlib.pyplot as plt from sklearn.model_selection import train_test_split from sklearn.metrics import roc_auc_score, precision_recall_curve from sklearn.linear_model import LogisticRegression from sklearn.ensemble import RandomForestClassifier from scipy.optimize import minimize from scipy.sparse import csr_matrix from collections import defaultdict def generate_partial_network(G, missing_fraction=0.3): \"\"\"Generate partial network by removing edges\"\"\" edges = list(G.edges()) n_remove = int(len(edges) * missing_fraction) edges_to_remove = np.random.choice(len(edges), n_remove, replace=False) partial_G = G.copy() partial_G.remove_edges_from([edges[i] for i in edges_to_remove]) return partial_G, edges_to_remove def calculate_similarity_measures(G): \"\"\"Calculate various similarity measures for link prediction\"\"\" n = G.number_of_nodes() similarities = {} # Common neighbors cn = np.zeros((n, n)) for i in range(n): for j in range(i+1, n): cn[i, j] = len(set(G.neighbors(i)) \u0026 set(G.neighbors(j))) cn[j, i] = cn[i, j] similarities['common_neighbors'] = cn # Jaccard coefficient jaccard = np.zeros((n, n)) for i in range(n): for j in range(i+1, n): neighbors_i = set(G.neighbors(i)) neighbors_j = set(G.neighbors(j)) union = neighbors_i | neighbors_j if len(union) \u003e 0: jaccard[i, j] = len(neighbors_i \u0026 neighbors_j) / len(union) jaccard[j, i] = jaccard[i, j] similarities['jaccard'] = jaccard # Adamic-Adar aa = np.zeros((n, n)) for i in range(n): for j in range(i+1, n): common_neighbors = set(G.neighbors(i)) \u0026 set(G.neighbors(j)) aa[i, j] = sum(1/np.log(G.degree(k)) for k in common_neighbors if G.degree(k) \u003e 1) aa[j, i] = aa[i, j] similarities['adamic_adar'] = aa # Preferential attachment pa = np.zeros((n, n)) degrees = [G.degree(i) for i in range(n)] for i in range(n): for j in range(i+1, n): pa[i, j] = degrees[i] * degrees[j] pa[j, i] = pa[i, j] similarities['preferential_attachment'] = pa return similarities def predict_links(G, similarities, method='common_neighbors'): \"\"\"Predict links using similarity measures\"\"\" n = G.number_of_nodes() A = nx.adjacency_matrix(G).toarray() # Get similarity scores scores = similarities[method] # Create training and test sets edges = [(i, j) for i in range(n) for j in range(i+1, n)] labels = [A[i, j] for i, j in edges] features = [scores[i, j] for i, j in edges] X_train, X_test, y_train, y_test = train_test_split( features, labels, test_size=0.3, random_state=42 ) # Train classifier clf = LogisticRegression(random_state=42) clf.fit(np.array(X_train).reshape(-1, 1), y_train) # Predict probabilities y_pred_proba = clf.predict_proba(np.array(X_test).reshape(-1, 1))[:, 1] y_pred = clf.predict(np.array(X_test).reshape(-1, 1)) # Calculate metrics auc = roc_auc_score(y_test, y_pred_proba) precision, recall, _ = precision_recall_curve(y_test, y_pred_proba) return { 'auc': auc, 'precision': precision, 'recall': recall, 'y_test': y_test, 'y_pred_proba': y_pred_proba } def matrix_completion(A_observed, rank=5, lambda_reg=0.1): \"\"\"Perform matrix completion using nuclear norm minimization\"\"\" def objective(X_flat): X = X_flat.reshape(A_observed.shape) # Nuclear norm (sum of singular values) U, s, Vt = np.linalg.svd(X, full_matrices=False) nuclear_norm = np.sum(s) # Frobenius norm of observed entries mask = ~np.isnan(A_observed) frobenius_norm = np.sum((X[mask] - A_observed[mask])**2) return frobenius_norm + lambda_reg * nuclear_norm # Initialize with random matrix X_init = np.random.randn(*A_observed.shape) X_init = X_init.flatten() # Optimize result = minimize(objective, X_init, method='L-BFGS-B') X_completed = result.x.reshape(A_observed.shape) return X_completed def impute_missing_data(A, method='mean'): \"\"\"Impute missing data in adjacency matrix\"\"\" A_imputed = A.copy() if method == 'mean': # Mean imputation mean_val = np.nanmean(A) A_imputed[np.isnan(A)] = mean_val elif method == 'regression': # Regression imputation for j in range(A.shape[1]): missing_mask = np.isnan(A[:, j]) if np.any(missing_mask) and not np.all(missing_mask): # Use other columns to predict missing values X = A[:, ~missing_mask] y = A[~missing_mask, j] if X.shape[1] \u003e 0: # Simple linear regression beta = np.linalg.lstsq(X, y, rcond=None)[0] A_imputed[missing_mask, j] = X[missing_mask] @ beta elif method == 'matrix_completion': # Matrix completion A_imputed = matrix_completion(A) return A_imputed def evaluate_reconstruction(G_original, G_reconstructed): \"\"\"Evaluate network reconstruction quality\"\"\" A_original = nx.adjacency_matrix(G_original).toarray() A_reconstructed = nx.adjacency_matrix(G_reconstructed).toarray() # Edge accuracy edge_accuracy = np.mean(A_original == A_reconstructed) # Precision and recall tp = np.sum((A_original == 1) \u0026 (A_reconstructed == 1)) fp = np.sum((A_original == 0) \u0026 (A_reconstructed == 1)) fn = np.sum((A_original == 1) \u0026 (A_reconstructed == 0)) precision = tp / (tp + fp) if (tp + fp) \u003e 0 else 0 recall = tp / (tp + fn) if (tp + fn) \u003e 0 else 0 f1 = 2 * precision * recall / (precision + recall) if (precision + recall) \u003e 0 else 0 # Structural similarity degree_correlation = np.corrcoef( [G_original.degree(i) for i in G_original.nodes()], [G_reconstructed.degree(i) for i in G_reconstructed.nodes()] )[0, 1] return { 'edge_accuracy': edge_accuracy, 'precision': precision, 'recall': recall, 'f1': f1, 'degree_correlation': degree_correlation } def plot_inference_results(G_original, G_partial, G_reconstructed, link_prediction_results, title=\"Network Inference\"): \"\"\"Plot network inference results\"\"\" fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12)) # Original network pos = nx.spring_layout(G_original, k=1, iterations=50) nx.draw(G_original, pos, ax=ax1, node_color='lightblue', edge_color='gray', alpha=0.6, node_size=50) ax1.set_title('Original Network') ax1.axis('off') # Partial network nx.draw(G_partial, pos, ax=ax2, node_color='lightcoral', edge_color='gray', alpha=0.6, node_size=50) ax2.set_title('Partial Network (Missing Edges)') ax2.axis('off') # Reconstructed network nx.draw(G_reconstructed, pos, ax=ax3, node_color='lightgreen', edge_color='gray', alpha=0.6, node_size=50) ax3.set_title('Reconstructed Network') ax3.axis('off') # Link prediction ROC curve if 'y_test' in link_prediction_results and 'y_pred_proba' in link_prediction_results: from sklearn.metrics import roc_curve fpr, tpr, _ = roc_curve(link_prediction_results['y_test'], link_prediction_results['y_pred_proba']) ax4.plot(fpr, tpr, 'b-', linewidth=2, label=f'AUC = {link_prediction_results[\"auc\"]:.3f}') ax4.plot([0, 1], [0, 1], 'r--', alpha=0.5) ax4.set_xlabel('False Positive Rate') ax4.set_ylabel('True Positive Rate') ax4.set_title('Link Prediction ROC Curve') ax4.legend() ax4.grid(True, alpha=0.3) plt.suptitle(title) plt.tight_layout() plt.show() # Example: Network inference G = nx.barabasi_albert_graph(50, 3) # Generate partial network G_partial, removed_edges = generate_partial_network(G, missing_fraction=0.3) # Calculate similarity measures similarities = calculate_similarity_measures(G_partial) # Predict links link_prediction_results = predict_links(G_partial, similarities, method='common_neighbors') # Reconstruct network A_partial = nx.adjacency_matrix(G_partial).toarray() A_reconstructed = impute_missing_data(A_partial, method='matrix_completion') # Create reconstructed network G_reconstructed = nx.from_numpy_array(A_reconstructed) G_reconstructed = nx.Graph(G_reconstructed) # Remove self-loops and parallel edges # Evaluate reconstruction evaluation = evaluate_reconstruction(G, G_reconstructed) print(\"Network Inference Results:\") print(f\"Edge accuracy: {evaluation['edge_accuracy']:.3f}\") print(f\"Precision: {evaluation['precision']:.3f}\") print(f\"Recall: {evaluation['recall']:.3f}\") print(f\"F1-score: {evaluation['f1']:.3f}\") print(f\"Degree correlation: {evaluation['degree_correlation']:.3f}\") print(f\"Link prediction AUC: {link_prediction_results['auc']:.3f}\") # Plot results plot_inference_results(G, G_partial, G_reconstructed, link_prediction_results) Key Takeaways Statistical inference: Maximum likelihood and Bayesian methods for parameter estimation Link prediction: Various similarity measures for predicting missing edges Matrix completion: Nuclear norm minimization for network reconstruction Missing data: Different types and imputation methods Network tomography: Inferring topology from partial observations Applications: Important for materials science and defect networks Evaluation: Multiple metrics for assessing reconstruction quality References Newman, M. E. J. (2010). Networks: An Introduction. Oxford University Press. Liben-Nowell, D., \u0026 Kleinberg, J. (2007). The link-prediction problem for social networks. Journal of the American Society for Information Science and Technology, 58(7), 1019-1031. Candès, E. J., \u0026 Recht, B. (2009). Exact matrix completion via convex optimization. Foundations of Computational Mathematics, 9(6), 717-772. Kipf, T. N., \u0026 Welling, M. (2016). Semi-supervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907. Network inference provides powerful tools for reconstructing network structure from partial data, with important applications in materials science and complex systems.\n",
  "wordCount" : "1926",
  "inLanguage": "en",
  "datePublished": "2025-08-29T00:00:00Z",
  "dateModified": "2025-08-29T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Linlin-resh"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://Linlin-resh.github.io/posts/reading-notes-newman-ch12/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Notes on AI4Science \u0026 Graph Theory",
    "logo": {
      "@type": "ImageObject",
      "url": "https://Linlin-resh.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://Linlin-resh.github.io/" accesskey="h" title="Notes on AI4Science &amp; Graph Theory (Alt + H)">Notes on AI4Science &amp; Graph Theory</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://Linlin-resh.github.io/" title="Home">
                    <span>Home</span>
                </a>
            </li>
            <li>
                <a href="https://Linlin-resh.github.io/posts/" title="Blog">
                    <span>Blog</span>
                </a>
            </li>
            <li>
                <a href="https://Linlin-resh.github.io/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="https://Linlin-resh.github.io/about/" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="https://Linlin-resh.github.io/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Reading Notes: Newman&#39;s Networks Chapter 12 - Network Inference
    </h1>
    <div class="post-description">
      Study notes for Chapter 12 of Newman&#39;s &#39;Networks: An Introduction&#39; covering statistical inference, network reconstruction, and missing data imputation
    </div>
    <div class="post-meta"><span title='2025-08-29 00:00:00 +0000 UTC'>August 29, 2025</span>&nbsp;·&nbsp;10 min&nbsp;·&nbsp;1926 words&nbsp;·&nbsp;Linlin-resh

</div>
  </header> <div class="toc">
    <details  open>
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#introduction" aria-label="Introduction">Introduction</a></li>
                <li>
                    <a href="#121-statistical-inference" aria-label="12.1 Statistical Inference">12.1 Statistical Inference</a><ul>
                        
                <li>
                    <a href="#maximum-likelihood-estimation" aria-label="Maximum Likelihood Estimation">Maximum Likelihood Estimation</a><ul>
                        
                <li>
                    <a href="#likelihood-function" aria-label="Likelihood Function">Likelihood Function</a></li>
                <li>
                    <a href="#log-likelihood" aria-label="Log-Likelihood">Log-Likelihood</a></li>
                <li>
                    <a href="#gradient-descent" aria-label="Gradient Descent">Gradient Descent</a></li></ul>
                </li>
                <li>
                    <a href="#bayesian-inference" aria-label="Bayesian Inference">Bayesian Inference</a><ul>
                        
                <li>
                    <a href="#prior-distribution" aria-label="Prior Distribution">Prior Distribution</a></li>
                <li>
                    <a href="#posterior-distribution" aria-label="Posterior Distribution">Posterior Distribution</a></li>
                <li>
                    <a href="#markov-chain-monte-carlo" aria-label="Markov Chain Monte Carlo">Markov Chain Monte Carlo</a></li></ul>
                </li>
                <li>
                    <a href="#model-selection" aria-label="Model Selection">Model Selection</a><ul>
                        
                <li>
                    <a href="#information-criteria" aria-label="Information Criteria">Information Criteria</a></li>
                <li>
                    <a href="#cross-validation" aria-label="Cross-Validation">Cross-Validation</a></li></ul>
                </li></ul>
                </li>
                <li>
                    <a href="#122-network-reconstruction" aria-label="12.2 Network Reconstruction">12.2 Network Reconstruction</a><ul>
                        
                <li>
                    <a href="#link-prediction" aria-label="Link Prediction">Link Prediction</a><ul>
                        
                <li>
                    <a href="#similarity-measures" aria-label="Similarity Measures">Similarity Measures</a></li>
                <li>
                    <a href="#prediction-accuracy" aria-label="Prediction Accuracy">Prediction Accuracy</a></li></ul>
                </li>
                <li>
                    <a href="#matrix-completion" aria-label="Matrix Completion">Matrix Completion</a><ul>
                        
                <li>
                    <a href="#nuclear-norm-minimization" aria-label="Nuclear Norm Minimization">Nuclear Norm Minimization</a></li>
                <li>
                    <a href="#alternating-least-squares" aria-label="Alternating Least Squares">Alternating Least Squares</a></li></ul>
                </li>
                <li>
                    <a href="#graph-neural-networks" aria-label="Graph Neural Networks">Graph Neural Networks</a><ul>
                        
                <li>
                    <a href="#graph-convolutional-networks" aria-label="Graph Convolutional Networks">Graph Convolutional Networks</a></li>
                <li>
                    <a href="#link-prediction-with-gnns" aria-label="Link Prediction with GNNs">Link Prediction with GNNs</a></li></ul>
                </li></ul>
                </li>
                <li>
                    <a href="#123-missing-data-imputation" aria-label="12.3 Missing Data Imputation">12.3 Missing Data Imputation</a><ul>
                        
                <li>
                    <a href="#missing-data-types" aria-label="Missing Data Types">Missing Data Types</a><ul>
                        
                <li>
                    <a href="#missing-completely-at-random-mcar" aria-label="Missing Completely at Random (MCAR)">Missing Completely at Random (MCAR)</a></li>
                <li>
                    <a href="#missing-at-random-mar" aria-label="Missing at Random (MAR)">Missing at Random (MAR)</a></li>
                <li>
                    <a href="#missing-not-at-random-mnar" aria-label="Missing Not at Random (MNAR)">Missing Not at Random (MNAR)</a></li></ul>
                </li>
                <li>
                    <a href="#imputation-methods" aria-label="Imputation Methods">Imputation Methods</a><ul>
                        
                <li>
                    <a href="#mean-imputation" aria-label="Mean Imputation">Mean Imputation</a></li>
                <li>
                    <a href="#regression-imputation" aria-label="Regression Imputation">Regression Imputation</a></li>
                <li>
                    <a href="#multiple-imputation" aria-label="Multiple Imputation">Multiple Imputation</a></li></ul>
                </li></ul>
                </li>
                <li>
                    <a href="#124-network-tomography" aria-label="12.4 Network Tomography">12.4 Network Tomography</a><ul>
                        
                <li>
                    <a href="#network-discovery" aria-label="Network Discovery">Network Discovery</a><ul>
                        
                <li>
                    <a href="#traceroute" aria-label="Traceroute">Traceroute</a></li>
                <li>
                    <a href="#ping" aria-label="Ping">Ping</a></li></ul>
                </li>
                <li>
                    <a href="#topology-inference" aria-label="Topology Inference">Topology Inference</a><ul>
                        
                <li>
                    <a href="#graph-construction" aria-label="Graph Construction">Graph Construction</a></li>
                <li>
                    <a href="#validation" aria-label="Validation">Validation</a></li></ul>
                </li></ul>
                </li>
                <li>
                    <a href="#125-applications-to-materials-science" aria-label="12.5 Applications to Materials Science">12.5 Applications to Materials Science</a><ul>
                        
                <li>
                    <a href="#defect-network-inference" aria-label="Defect Network Inference">Defect Network Inference</a><ul>
                        
                <li>
                    <a href="#problem" aria-label="Problem">Problem</a></li>
                <li>
                    <a href="#methods" aria-label="Methods">Methods</a></li></ul>
                </li>
                <li>
                    <a href="#nanowire-network-reconstruction" aria-label="Nanowire Network Reconstruction">Nanowire Network Reconstruction</a><ul>
                        
                <li>
                    <a href="#problem-1" aria-label="Problem">Problem</a></li>
                <li>
                    <a href="#optimization" aria-label="Optimization">Optimization</a></li></ul>
                </li>
                <li>
                    <a href="#phase-transition-inference" aria-label="Phase Transition Inference">Phase Transition Inference</a><ul>
                        
                <li>
                    <a href="#problem-2" aria-label="Problem">Problem</a></li>
                <li>
                    <a href="#methods-1" aria-label="Methods">Methods</a></li></ul>
                </li></ul>
                </li>
                <li>
                    <a href="#code-example-network-inference" aria-label="Code Example: Network Inference">Code Example: Network Inference</a></li>
                <li>
                    <a href="#key-takeaways" aria-label="Key Takeaways">Key Takeaways</a></li>
                <li>
                    <a href="#references" aria-label="References">References</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h2 id="introduction">Introduction<a hidden class="anchor" aria-hidden="true" href="#introduction">#</a></h2>
<p>Chapter 12 of Newman&rsquo;s <em>Networks: An Introduction</em> explores <strong>network inference</strong> - the process of reconstructing or inferring network structure from partial or noisy data. This chapter covers statistical methods, machine learning approaches, and practical techniques for network reconstruction.</p>
<h2 id="121-statistical-inference">12.1 Statistical Inference<a hidden class="anchor" aria-hidden="true" href="#121-statistical-inference">#</a></h2>
<h3 id="maximum-likelihood-estimation">Maximum Likelihood Estimation<a hidden class="anchor" aria-hidden="true" href="#maximum-likelihood-estimation">#</a></h3>
<h4 id="likelihood-function">Likelihood Function<a hidden class="anchor" aria-hidden="true" href="#likelihood-function">#</a></h4>
<p><strong>Likelihood function</strong>:
$$L(\theta) = \prod_{i,j} P(A_{ij}|\theta)$$</p>
<p>Where:</p>
<ul>
<li>$A_{ij}$: Observed adjacency matrix</li>
<li>$\theta$: Model parameters</li>
<li>$P(A_{ij}|\theta)$: Probability of edge $(i,j)$ given parameters</li>
</ul>
<h4 id="log-likelihood">Log-Likelihood<a hidden class="anchor" aria-hidden="true" href="#log-likelihood">#</a></h4>
<p><strong>Log-likelihood</strong>:
$$\ell(\theta) = \sum_{i,j} \log P(A_{ij}|\theta)$$</p>
<p><strong>MLE solution</strong>:
$$\hat{\theta} = \arg\max_{\theta} \ell(\theta)$$</p>
<h4 id="gradient-descent">Gradient Descent<a hidden class="anchor" aria-hidden="true" href="#gradient-descent">#</a></h4>
<p><strong>Gradient</strong>:
$$\frac{\partial \ell}{\partial \theta} = \sum_{i,j} \frac{1}{P(A_{ij}|\theta)} \frac{\partial P(A_{ij}|\theta)}{\partial \theta}$$</p>
<p><strong>Update rule</strong>:
$$\theta^{(t+1)} = \theta^{(t)} + \alpha \frac{\partial \ell}{\partial \theta}$$</p>
<h3 id="bayesian-inference">Bayesian Inference<a hidden class="anchor" aria-hidden="true" href="#bayesian-inference">#</a></h3>
<h4 id="prior-distribution">Prior Distribution<a hidden class="anchor" aria-hidden="true" href="#prior-distribution">#</a></h4>
<p><strong>Prior distribution</strong>:
$$P(\theta) = \text{prior knowledge about parameters}$$</p>
<p><strong>Common priors</strong>:</p>
<ul>
<li><strong>Uniform</strong>: $P(\theta) = \text{constant}$</li>
<li><strong>Gaussian</strong>: $P(\theta) = \mathcal{N}(\mu, \sigma^2)$</li>
<li><strong>Beta</strong>: $P(\theta) = \text{Beta}(\alpha, \beta)$</li>
</ul>
<h4 id="posterior-distribution">Posterior Distribution<a hidden class="anchor" aria-hidden="true" href="#posterior-distribution">#</a></h4>
<p><strong>Posterior distribution</strong>:
$$P(\theta|A) = \frac{P(A|\theta)P(\theta)}{P(A)}$$</p>
<p>Where $P(A)$ is the marginal likelihood:
$$P(A) = \int P(A|\theta)P(\theta) , d\theta$$</p>
<h4 id="markov-chain-monte-carlo">Markov Chain Monte Carlo<a hidden class="anchor" aria-hidden="true" href="#markov-chain-monte-carlo">#</a></h4>
<p><strong>Metropolis-Hastings algorithm</strong>:</p>
<ol>
<li>Propose new parameter $\theta&rsquo;$ from proposal distribution $q(\theta&rsquo;|\theta)$</li>
<li>Accept with probability:
$$P_{\text{accept}} = \min\left(1, \frac{P(\theta&rsquo;|A)q(\theta|\theta&rsquo;)}{P(\theta|A)q(\theta&rsquo;|\theta)}\right)$$</li>
<li>Repeat until convergence</li>
</ol>
<h3 id="model-selection">Model Selection<a hidden class="anchor" aria-hidden="true" href="#model-selection">#</a></h3>
<h4 id="information-criteria">Information Criteria<a hidden class="anchor" aria-hidden="true" href="#information-criteria">#</a></h4>
<p><strong>Akaike Information Criterion (AIC)</strong>:
$$AIC = -2\ell(\hat{\theta}) + 2k$$</p>
<p><strong>Bayesian Information Criterion (BIC)</strong>:
$$BIC = -2\ell(\hat{\theta}) + k \log n$$</p>
<p>Where $k$ is the number of parameters.</p>
<h4 id="cross-validation">Cross-Validation<a hidden class="anchor" aria-hidden="true" href="#cross-validation">#</a></h4>
<p><strong>k-fold cross-validation</strong>:</p>
<ol>
<li>Split data into $k$ folds</li>
<li>Train on $k-1$ folds, test on remaining fold</li>
<li>Repeat for all folds</li>
<li>Average performance</li>
</ol>
<h2 id="122-network-reconstruction">12.2 Network Reconstruction<a hidden class="anchor" aria-hidden="true" href="#122-network-reconstruction">#</a></h2>
<h3 id="link-prediction">Link Prediction<a hidden class="anchor" aria-hidden="true" href="#link-prediction">#</a></h3>
<h4 id="similarity-measures">Similarity Measures<a hidden class="anchor" aria-hidden="true" href="#similarity-measures">#</a></h4>
<p><strong>Common neighbors</strong>:
$$S_{ij} = |\mathcal{N}_i \cap \mathcal{N}_j|$$</p>
<p><strong>Jaccard coefficient</strong>:
$$S_{ij} = \frac{|\mathcal{N}_i \cap \mathcal{N}_j|}{|\mathcal{N}_i \cup \mathcal{N}_j|}$$</p>
<p><strong>Adamic-Adar</strong>:
$$S_{ij} = \sum_{k \in \mathcal{N}_i \cap \mathcal{N}_j} \frac{1}{\log k_k}$$</p>
<p><strong>Preferential attachment</strong>:
$$S_{ij} = k_i \cdot k_j$$</p>
<p><strong>Resource allocation</strong>:
$$S_{ij} = \sum_{k \in \mathcal{N}_i \cap \mathcal{N}_j} \frac{1}{k_k}$$</p>
<h4 id="prediction-accuracy">Prediction Accuracy<a hidden class="anchor" aria-hidden="true" href="#prediction-accuracy">#</a></h4>
<p><strong>Area Under Curve (AUC)</strong>:
$$AUC = \frac{1}{n(n-1)} \sum_{i \neq j} \mathbb{I}(S_{ij} &gt; S_{\text{random}})$$</p>
<p><strong>Precision</strong>:
$$P = \frac{TP}{TP + FP}$$</p>
<p><strong>Recall</strong>:
$$R = \frac{TP}{TP + FN}$$</p>
<p><strong>F1-score</strong>:
$$F1 = \frac{2PR}{P + R}$$</p>
<h3 id="matrix-completion">Matrix Completion<a hidden class="anchor" aria-hidden="true" href="#matrix-completion">#</a></h3>
<h4 id="nuclear-norm-minimization">Nuclear Norm Minimization<a hidden class="anchor" aria-hidden="true" href="#nuclear-norm-minimization">#</a></h4>
<p><strong>Problem</strong>:
$$\min_{X} ||X - A||<em>F^2 + \lambda ||X||</em>*$$</p>
<p>Where:</p>
<ul>
<li>$||X||_*$: Nuclear norm (sum of singular values)</li>
<li>$\lambda$: Regularization parameter</li>
</ul>
<h4 id="alternating-least-squares">Alternating Least Squares<a hidden class="anchor" aria-hidden="true" href="#alternating-least-squares">#</a></h4>
<p><strong>Algorithm</strong>:</p>
<ol>
<li>Initialize $U$ and $V$ randomly</li>
<li>Fix $V$, solve for $U$: $U = \arg\min_U ||UV^T - A||_F^2$</li>
<li>Fix $U$, solve for $V$: $V = \arg\min_V ||UV^T - A||_F^2$</li>
<li>Repeat until convergence</li>
</ol>
<p><strong>Solution</strong>: $X = UV^T$</p>
<h3 id="graph-neural-networks">Graph Neural Networks<a hidden class="anchor" aria-hidden="true" href="#graph-neural-networks">#</a></h3>
<h4 id="graph-convolutional-networks">Graph Convolutional Networks<a hidden class="anchor" aria-hidden="true" href="#graph-convolutional-networks">#</a></h4>
<p><strong>Layer update</strong>:
$$H^{(l+1)} = \sigma(\tilde{A} H^{(l)} W^{(l)})$$</p>
<p>Where:</p>
<ul>
<li>$\tilde{A} = D^{-1/2} A D^{-1/2}$: Normalized adjacency matrix</li>
<li>$H^{(l)}$: Node features at layer $l$</li>
<li>$W^{(l)}$: Weight matrix at layer $l$</li>
</ul>
<h4 id="link-prediction-with-gnns">Link Prediction with GNNs<a hidden class="anchor" aria-hidden="true" href="#link-prediction-with-gnns">#</a></h4>
<p><strong>Node embeddings</strong>:
$$z_i = \text{GNN}(A, X)_i$$</p>
<p><strong>Link prediction</strong>:
$$P(A_{ij} = 1) = \sigma(z_i^T z_j)$$</p>
<h2 id="123-missing-data-imputation">12.3 Missing Data Imputation<a hidden class="anchor" aria-hidden="true" href="#123-missing-data-imputation">#</a></h2>
<h3 id="missing-data-types">Missing Data Types<a hidden class="anchor" aria-hidden="true" href="#missing-data-types">#</a></h3>
<h4 id="missing-completely-at-random-mcar">Missing Completely at Random (MCAR)<a hidden class="anchor" aria-hidden="true" href="#missing-completely-at-random-mcar">#</a></h4>
<p><strong>Definition</strong>: Missingness is independent of observed and unobserved data</p>
<p><strong>Mathematical condition</strong>:
$$P(M|X, Y) = P(M)$$</p>
<p>Where $M$ is the missingness indicator.</p>
<h4 id="missing-at-random-mar">Missing at Random (MAR)<a hidden class="anchor" aria-hidden="true" href="#missing-at-random-mar">#</a></h4>
<p><strong>Definition</strong>: Missingness depends only on observed data</p>
<p><strong>Mathematical condition</strong>:
$$P(M|X, Y) = P(M|X)$$</p>
<h4 id="missing-not-at-random-mnar">Missing Not at Random (MNAR)<a hidden class="anchor" aria-hidden="true" href="#missing-not-at-random-mnar">#</a></h4>
<p><strong>Definition</strong>: Missingness depends on unobserved data</p>
<p><strong>Mathematical condition</strong>:
$$P(M|X, Y) \neq P(M|X)$$</p>
<h3 id="imputation-methods">Imputation Methods<a hidden class="anchor" aria-hidden="true" href="#imputation-methods">#</a></h3>
<h4 id="mean-imputation">Mean Imputation<a hidden class="anchor" aria-hidden="true" href="#mean-imputation">#</a></h4>
<p><strong>Method</strong>: Replace missing values with mean of observed values</p>
<p><strong>Formula</strong>:
$$\hat{x}<em>{ij} = \frac{1}{n_j} \sum</em>{i: x_{ij} \text{ observed}} x_{ij}$$</p>
<p><strong>Advantages</strong>: Simple, fast
<strong>Disadvantages</strong>: Reduces variance, may bias estimates</p>
<h4 id="regression-imputation">Regression Imputation<a hidden class="anchor" aria-hidden="true" href="#regression-imputation">#</a></h4>
<p><strong>Method</strong>: Use regression to predict missing values</p>
<p><strong>Formula</strong>:
$$\hat{x}<em>{ij} = \beta_0 + \sum</em>{k \neq j} \beta_k x_{ik}$$</p>
<p><strong>Advantages</strong>: Preserves relationships
<strong>Disadvantages</strong>: Assumes linear relationships</p>
<h4 id="multiple-imputation">Multiple Imputation<a hidden class="anchor" aria-hidden="true" href="#multiple-imputation">#</a></h4>
<p><strong>Method</strong>: Generate multiple imputed datasets</p>
<p><strong>Algorithm</strong>:</p>
<ol>
<li>Generate $m$ imputed datasets</li>
<li>Analyze each dataset separately</li>
<li>Combine results using Rubin&rsquo;s rules</li>
</ol>
<p><strong>Combined estimate</strong>:
$$\bar{\theta} = \frac{1}{m} \sum_{i=1}^m \hat{\theta}_i$$</p>
<p><strong>Variance</strong>:
$$\text{Var}(\bar{\theta}) = \frac{1}{m} \sum_{i=1}^m \text{Var}(\hat{\theta}<em>i) + \frac{1}{m-1} \sum</em>{i=1}^m (\hat{\theta}_i - \bar{\theta})^2$$</p>
<h2 id="124-network-tomography">12.4 Network Tomography<a hidden class="anchor" aria-hidden="true" href="#124-network-tomography">#</a></h2>
<h3 id="network-discovery">Network Discovery<a hidden class="anchor" aria-hidden="true" href="#network-discovery">#</a></h3>
<h4 id="traceroute">Traceroute<a hidden class="anchor" aria-hidden="true" href="#traceroute">#</a></h4>
<p><strong>Method</strong>: Send packets with increasing TTL values</p>
<p><strong>Information obtained</strong>:</p>
<ul>
<li>Path from source to destination</li>
<li>Round-trip time</li>
<li>Packet loss rate</li>
</ul>
<p><strong>Limitations</strong>:</p>
<ul>
<li>May not discover all paths</li>
<li>Load balancing can cause inconsistencies</li>
</ul>
<h4 id="ping">Ping<a hidden class="anchor" aria-hidden="true" href="#ping">#</a></h4>
<p><strong>Method</strong>: Send ICMP echo requests</p>
<p><strong>Information obtained</strong>:</p>
<ul>
<li>Round-trip time</li>
<li>Packet loss rate</li>
<li>Network reachability</li>
</ul>
<p><strong>Limitations</strong>:</p>
<ul>
<li>Only end-to-end information</li>
<li>May be blocked by firewalls</li>
</ul>
<h3 id="topology-inference">Topology Inference<a hidden class="anchor" aria-hidden="true" href="#topology-inference">#</a></h3>
<h4 id="graph-construction">Graph Construction<a hidden class="anchor" aria-hidden="true" href="#graph-construction">#</a></h4>
<p><strong>From traceroute data</strong>:</p>
<ol>
<li>Collect paths from multiple sources to multiple destinations</li>
<li>Construct graph by connecting consecutive nodes in paths</li>
<li>Merge duplicate edges</li>
</ol>
<p><strong>From ping data</strong>:</p>
<ol>
<li>Test connectivity between all pairs of nodes</li>
<li>Add edge if nodes can communicate</li>
<li>May miss intermediate nodes</li>
</ol>
<h4 id="validation">Validation<a hidden class="anchor" aria-hidden="true" href="#validation">#</a></h4>
<p><strong>Consistency checks</strong>:</p>
<ul>
<li><strong>Triangle inequality</strong>: $d_{ij} \leq d_{ik} + d_{kj}$</li>
<li><strong>Symmetry</strong>: $d_{ij} = d_{ji}$</li>
<li><strong>Transitivity</strong>: If $A_{ik} = 1$ and $A_{kj} = 1$, then $A_{ij} = 1$</li>
</ul>
<p><strong>Statistical validation</strong>:</p>
<ul>
<li>Compare inferred topology with known topology</li>
<li>Use cross-validation techniques</li>
</ul>
<h2 id="125-applications-to-materials-science">12.5 Applications to Materials Science<a hidden class="anchor" aria-hidden="true" href="#125-applications-to-materials-science">#</a></h2>
<h3 id="defect-network-inference">Defect Network Inference<a hidden class="anchor" aria-hidden="true" href="#defect-network-inference">#</a></h3>
<h4 id="problem">Problem<a hidden class="anchor" aria-hidden="true" href="#problem">#</a></h4>
<p><strong>Given</strong>: Partial observations of defect interactions
<strong>Goal</strong>: Infer complete defect network structure</p>
<p><strong>Mathematical formulation</strong>:
$$\min_{A} ||A - A_{\text{observed}}||_F^2 + \lambda R(A)$$</p>
<p>Where $R(A)$ is a regularization term.</p>
<h4 id="methods">Methods<a hidden class="anchor" aria-hidden="true" href="#methods">#</a></h4>
<p><strong>Sparse reconstruction</strong>:
$$R(A) = ||A||_1$$</p>
<p><strong>Low-rank reconstruction</strong>:
$$R(A) = ||A||_*$$</p>
<p><strong>Community structure</strong>:
$$R(A) = \sum_{c} ||A_c||_F^2$$</p>
<h3 id="nanowire-network-reconstruction">Nanowire Network Reconstruction<a hidden class="anchor" aria-hidden="true" href="#nanowire-network-reconstruction">#</a></h3>
<h4 id="problem-1">Problem<a hidden class="anchor" aria-hidden="true" href="#problem-1">#</a></h4>
<p><strong>Given</strong>: Partial electrical measurements
<strong>Goal</strong>: Infer complete nanowire network</p>
<p><strong>Constraints</strong>:</p>
<ul>
<li><strong>Electrical</strong>: Ohm&rsquo;s law must be satisfied</li>
<li><strong>Topological</strong>: Network must be connected</li>
<li><strong>Physical</strong>: Edge weights must be positive</li>
</ul>
<h4 id="optimization">Optimization<a hidden class="anchor" aria-hidden="true" href="#optimization">#</a></h4>
<p><strong>Objective function</strong>:
$$\min_{A, R} \sum_{i,j} (V_i - V_j - R_{ij} I_{ij})^2 + \lambda ||A||_1$$</p>
<p><strong>Constraints</strong>:</p>
<ul>
<li>$A_{ij} \geq 0$ (positive resistance)</li>
<li>$A_{ij} = 0$ if no nanowire between $i$ and $j$</li>
<li>$\sum_j A_{ij} &gt; 0$ (each node must have at least one connection)</li>
</ul>
<h3 id="phase-transition-inference">Phase Transition Inference<a hidden class="anchor" aria-hidden="true" href="#phase-transition-inference">#</a></h3>
<h4 id="problem-2">Problem<a hidden class="anchor" aria-hidden="true" href="#problem-2">#</a></h4>
<p><strong>Given</strong>: Partial observations of phase transitions
<strong>Goal</strong>: Infer complete phase diagram</p>
<p><strong>Network representation</strong>:</p>
<ul>
<li><strong>Nodes</strong>: Different phases</li>
<li><strong>Edges</strong>: Phase transitions</li>
<li><strong>Weights</strong>: Transition probabilities</li>
</ul>
<h4 id="methods-1">Methods<a hidden class="anchor" aria-hidden="true" href="#methods-1">#</a></h4>
<p><strong>Bayesian inference</strong>:
$$P(\text{phase}|T, P) = \frac{P(T, P|\text{phase})P(\text{phase})}{P(T, P)}$$</p>
<p><strong>Machine learning</strong>:
$$f: (T, P) \rightarrow \text{phase}$$</p>
<h2 id="code-example-network-inference">Code Example: Network Inference<a hidden class="anchor" aria-hidden="true" href="#code-example-network-inference">#</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#ff79c6">import</span> networkx <span style="color:#ff79c6">as</span> nx
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">import</span> numpy <span style="color:#ff79c6">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">import</span> matplotlib.pyplot <span style="color:#ff79c6">as</span> plt
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">from</span> sklearn.model_selection <span style="color:#ff79c6">import</span> train_test_split
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">from</span> sklearn.metrics <span style="color:#ff79c6">import</span> roc_auc_score, precision_recall_curve
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">from</span> sklearn.linear_model <span style="color:#ff79c6">import</span> LogisticRegression
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">from</span> sklearn.ensemble <span style="color:#ff79c6">import</span> RandomForestClassifier
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">from</span> scipy.optimize <span style="color:#ff79c6">import</span> minimize
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">from</span> scipy.sparse <span style="color:#ff79c6">import</span> csr_matrix
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">from</span> collections <span style="color:#ff79c6">import</span> defaultdict
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">def</span> <span style="color:#50fa7b">generate_partial_network</span>(G, missing_fraction<span style="color:#ff79c6">=</span><span style="color:#bd93f9">0.3</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#f1fa8c">&#34;&#34;&#34;Generate partial network by removing edges&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    edges <span style="color:#ff79c6">=</span> <span style="color:#8be9fd;font-style:italic">list</span>(G<span style="color:#ff79c6">.</span>edges())
</span></span><span style="display:flex;"><span>    n_remove <span style="color:#ff79c6">=</span> <span style="color:#8be9fd;font-style:italic">int</span>(<span style="color:#8be9fd;font-style:italic">len</span>(edges) <span style="color:#ff79c6">*</span> missing_fraction)
</span></span><span style="display:flex;"><span>    edges_to_remove <span style="color:#ff79c6">=</span> np<span style="color:#ff79c6">.</span>random<span style="color:#ff79c6">.</span>choice(<span style="color:#8be9fd;font-style:italic">len</span>(edges), n_remove, replace<span style="color:#ff79c6">=</span><span style="color:#ff79c6">False</span>)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    partial_G <span style="color:#ff79c6">=</span> G<span style="color:#ff79c6">.</span>copy()
</span></span><span style="display:flex;"><span>    partial_G<span style="color:#ff79c6">.</span>remove_edges_from([edges[i] <span style="color:#ff79c6">for</span> i <span style="color:#ff79c6">in</span> edges_to_remove])
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">return</span> partial_G, edges_to_remove
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">def</span> <span style="color:#50fa7b">calculate_similarity_measures</span>(G):
</span></span><span style="display:flex;"><span>    <span style="color:#f1fa8c">&#34;&#34;&#34;Calculate various similarity measures for link prediction&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    n <span style="color:#ff79c6">=</span> G<span style="color:#ff79c6">.</span>number_of_nodes()
</span></span><span style="display:flex;"><span>    similarities <span style="color:#ff79c6">=</span> {}
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4"># Common neighbors</span>
</span></span><span style="display:flex;"><span>    cn <span style="color:#ff79c6">=</span> np<span style="color:#ff79c6">.</span>zeros((n, n))
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">for</span> i <span style="color:#ff79c6">in</span> <span style="color:#8be9fd;font-style:italic">range</span>(n):
</span></span><span style="display:flex;"><span>        <span style="color:#ff79c6">for</span> j <span style="color:#ff79c6">in</span> <span style="color:#8be9fd;font-style:italic">range</span>(i<span style="color:#ff79c6">+</span><span style="color:#bd93f9">1</span>, n):
</span></span><span style="display:flex;"><span>            cn[i, j] <span style="color:#ff79c6">=</span> <span style="color:#8be9fd;font-style:italic">len</span>(<span style="color:#8be9fd;font-style:italic">set</span>(G<span style="color:#ff79c6">.</span>neighbors(i)) <span style="color:#ff79c6">&amp;</span> <span style="color:#8be9fd;font-style:italic">set</span>(G<span style="color:#ff79c6">.</span>neighbors(j)))
</span></span><span style="display:flex;"><span>            cn[j, i] <span style="color:#ff79c6">=</span> cn[i, j]
</span></span><span style="display:flex;"><span>    similarities[<span style="color:#f1fa8c">&#39;common_neighbors&#39;</span>] <span style="color:#ff79c6">=</span> cn
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4"># Jaccard coefficient</span>
</span></span><span style="display:flex;"><span>    jaccard <span style="color:#ff79c6">=</span> np<span style="color:#ff79c6">.</span>zeros((n, n))
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">for</span> i <span style="color:#ff79c6">in</span> <span style="color:#8be9fd;font-style:italic">range</span>(n):
</span></span><span style="display:flex;"><span>        <span style="color:#ff79c6">for</span> j <span style="color:#ff79c6">in</span> <span style="color:#8be9fd;font-style:italic">range</span>(i<span style="color:#ff79c6">+</span><span style="color:#bd93f9">1</span>, n):
</span></span><span style="display:flex;"><span>            neighbors_i <span style="color:#ff79c6">=</span> <span style="color:#8be9fd;font-style:italic">set</span>(G<span style="color:#ff79c6">.</span>neighbors(i))
</span></span><span style="display:flex;"><span>            neighbors_j <span style="color:#ff79c6">=</span> <span style="color:#8be9fd;font-style:italic">set</span>(G<span style="color:#ff79c6">.</span>neighbors(j))
</span></span><span style="display:flex;"><span>            union <span style="color:#ff79c6">=</span> neighbors_i <span style="color:#ff79c6">|</span> neighbors_j
</span></span><span style="display:flex;"><span>            <span style="color:#ff79c6">if</span> <span style="color:#8be9fd;font-style:italic">len</span>(union) <span style="color:#ff79c6">&gt;</span> <span style="color:#bd93f9">0</span>:
</span></span><span style="display:flex;"><span>                jaccard[i, j] <span style="color:#ff79c6">=</span> <span style="color:#8be9fd;font-style:italic">len</span>(neighbors_i <span style="color:#ff79c6">&amp;</span> neighbors_j) <span style="color:#ff79c6">/</span> <span style="color:#8be9fd;font-style:italic">len</span>(union)
</span></span><span style="display:flex;"><span>                jaccard[j, i] <span style="color:#ff79c6">=</span> jaccard[i, j]
</span></span><span style="display:flex;"><span>    similarities[<span style="color:#f1fa8c">&#39;jaccard&#39;</span>] <span style="color:#ff79c6">=</span> jaccard
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4"># Adamic-Adar</span>
</span></span><span style="display:flex;"><span>    aa <span style="color:#ff79c6">=</span> np<span style="color:#ff79c6">.</span>zeros((n, n))
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">for</span> i <span style="color:#ff79c6">in</span> <span style="color:#8be9fd;font-style:italic">range</span>(n):
</span></span><span style="display:flex;"><span>        <span style="color:#ff79c6">for</span> j <span style="color:#ff79c6">in</span> <span style="color:#8be9fd;font-style:italic">range</span>(i<span style="color:#ff79c6">+</span><span style="color:#bd93f9">1</span>, n):
</span></span><span style="display:flex;"><span>            common_neighbors <span style="color:#ff79c6">=</span> <span style="color:#8be9fd;font-style:italic">set</span>(G<span style="color:#ff79c6">.</span>neighbors(i)) <span style="color:#ff79c6">&amp;</span> <span style="color:#8be9fd;font-style:italic">set</span>(G<span style="color:#ff79c6">.</span>neighbors(j))
</span></span><span style="display:flex;"><span>            aa[i, j] <span style="color:#ff79c6">=</span> <span style="color:#8be9fd;font-style:italic">sum</span>(<span style="color:#bd93f9">1</span><span style="color:#ff79c6">/</span>np<span style="color:#ff79c6">.</span>log(G<span style="color:#ff79c6">.</span>degree(k)) <span style="color:#ff79c6">for</span> k <span style="color:#ff79c6">in</span> common_neighbors <span style="color:#ff79c6">if</span> G<span style="color:#ff79c6">.</span>degree(k) <span style="color:#ff79c6">&gt;</span> <span style="color:#bd93f9">1</span>)
</span></span><span style="display:flex;"><span>            aa[j, i] <span style="color:#ff79c6">=</span> aa[i, j]
</span></span><span style="display:flex;"><span>    similarities[<span style="color:#f1fa8c">&#39;adamic_adar&#39;</span>] <span style="color:#ff79c6">=</span> aa
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4"># Preferential attachment</span>
</span></span><span style="display:flex;"><span>    pa <span style="color:#ff79c6">=</span> np<span style="color:#ff79c6">.</span>zeros((n, n))
</span></span><span style="display:flex;"><span>    degrees <span style="color:#ff79c6">=</span> [G<span style="color:#ff79c6">.</span>degree(i) <span style="color:#ff79c6">for</span> i <span style="color:#ff79c6">in</span> <span style="color:#8be9fd;font-style:italic">range</span>(n)]
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">for</span> i <span style="color:#ff79c6">in</span> <span style="color:#8be9fd;font-style:italic">range</span>(n):
</span></span><span style="display:flex;"><span>        <span style="color:#ff79c6">for</span> j <span style="color:#ff79c6">in</span> <span style="color:#8be9fd;font-style:italic">range</span>(i<span style="color:#ff79c6">+</span><span style="color:#bd93f9">1</span>, n):
</span></span><span style="display:flex;"><span>            pa[i, j] <span style="color:#ff79c6">=</span> degrees[i] <span style="color:#ff79c6">*</span> degrees[j]
</span></span><span style="display:flex;"><span>            pa[j, i] <span style="color:#ff79c6">=</span> pa[i, j]
</span></span><span style="display:flex;"><span>    similarities[<span style="color:#f1fa8c">&#39;preferential_attachment&#39;</span>] <span style="color:#ff79c6">=</span> pa
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">return</span> similarities
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">def</span> <span style="color:#50fa7b">predict_links</span>(G, similarities, method<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#39;common_neighbors&#39;</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#f1fa8c">&#34;&#34;&#34;Predict links using similarity measures&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    n <span style="color:#ff79c6">=</span> G<span style="color:#ff79c6">.</span>number_of_nodes()
</span></span><span style="display:flex;"><span>    A <span style="color:#ff79c6">=</span> nx<span style="color:#ff79c6">.</span>adjacency_matrix(G)<span style="color:#ff79c6">.</span>toarray()
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4"># Get similarity scores</span>
</span></span><span style="display:flex;"><span>    scores <span style="color:#ff79c6">=</span> similarities[method]
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4"># Create training and test sets</span>
</span></span><span style="display:flex;"><span>    edges <span style="color:#ff79c6">=</span> [(i, j) <span style="color:#ff79c6">for</span> i <span style="color:#ff79c6">in</span> <span style="color:#8be9fd;font-style:italic">range</span>(n) <span style="color:#ff79c6">for</span> j <span style="color:#ff79c6">in</span> <span style="color:#8be9fd;font-style:italic">range</span>(i<span style="color:#ff79c6">+</span><span style="color:#bd93f9">1</span>, n)]
</span></span><span style="display:flex;"><span>    labels <span style="color:#ff79c6">=</span> [A[i, j] <span style="color:#ff79c6">for</span> i, j <span style="color:#ff79c6">in</span> edges]
</span></span><span style="display:flex;"><span>    features <span style="color:#ff79c6">=</span> [scores[i, j] <span style="color:#ff79c6">for</span> i, j <span style="color:#ff79c6">in</span> edges]
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    X_train, X_test, y_train, y_test <span style="color:#ff79c6">=</span> train_test_split(
</span></span><span style="display:flex;"><span>        features, labels, test_size<span style="color:#ff79c6">=</span><span style="color:#bd93f9">0.3</span>, random_state<span style="color:#ff79c6">=</span><span style="color:#bd93f9">42</span>
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4"># Train classifier</span>
</span></span><span style="display:flex;"><span>    clf <span style="color:#ff79c6">=</span> LogisticRegression(random_state<span style="color:#ff79c6">=</span><span style="color:#bd93f9">42</span>)
</span></span><span style="display:flex;"><span>    clf<span style="color:#ff79c6">.</span>fit(np<span style="color:#ff79c6">.</span>array(X_train)<span style="color:#ff79c6">.</span>reshape(<span style="color:#ff79c6">-</span><span style="color:#bd93f9">1</span>, <span style="color:#bd93f9">1</span>), y_train)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4"># Predict probabilities</span>
</span></span><span style="display:flex;"><span>    y_pred_proba <span style="color:#ff79c6">=</span> clf<span style="color:#ff79c6">.</span>predict_proba(np<span style="color:#ff79c6">.</span>array(X_test)<span style="color:#ff79c6">.</span>reshape(<span style="color:#ff79c6">-</span><span style="color:#bd93f9">1</span>, <span style="color:#bd93f9">1</span>))[:, <span style="color:#bd93f9">1</span>]
</span></span><span style="display:flex;"><span>    y_pred <span style="color:#ff79c6">=</span> clf<span style="color:#ff79c6">.</span>predict(np<span style="color:#ff79c6">.</span>array(X_test)<span style="color:#ff79c6">.</span>reshape(<span style="color:#ff79c6">-</span><span style="color:#bd93f9">1</span>, <span style="color:#bd93f9">1</span>))
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4"># Calculate metrics</span>
</span></span><span style="display:flex;"><span>    auc <span style="color:#ff79c6">=</span> roc_auc_score(y_test, y_pred_proba)
</span></span><span style="display:flex;"><span>    precision, recall, _ <span style="color:#ff79c6">=</span> precision_recall_curve(y_test, y_pred_proba)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">return</span> {
</span></span><span style="display:flex;"><span>        <span style="color:#f1fa8c">&#39;auc&#39;</span>: auc,
</span></span><span style="display:flex;"><span>        <span style="color:#f1fa8c">&#39;precision&#39;</span>: precision,
</span></span><span style="display:flex;"><span>        <span style="color:#f1fa8c">&#39;recall&#39;</span>: recall,
</span></span><span style="display:flex;"><span>        <span style="color:#f1fa8c">&#39;y_test&#39;</span>: y_test,
</span></span><span style="display:flex;"><span>        <span style="color:#f1fa8c">&#39;y_pred_proba&#39;</span>: y_pred_proba
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">def</span> <span style="color:#50fa7b">matrix_completion</span>(A_observed, rank<span style="color:#ff79c6">=</span><span style="color:#bd93f9">5</span>, lambda_reg<span style="color:#ff79c6">=</span><span style="color:#bd93f9">0.1</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#f1fa8c">&#34;&#34;&#34;Perform matrix completion using nuclear norm minimization&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">def</span> <span style="color:#50fa7b">objective</span>(X_flat):
</span></span><span style="display:flex;"><span>        X <span style="color:#ff79c6">=</span> X_flat<span style="color:#ff79c6">.</span>reshape(A_observed<span style="color:#ff79c6">.</span>shape)
</span></span><span style="display:flex;"><span>        <span style="color:#6272a4"># Nuclear norm (sum of singular values)</span>
</span></span><span style="display:flex;"><span>        U, s, Vt <span style="color:#ff79c6">=</span> np<span style="color:#ff79c6">.</span>linalg<span style="color:#ff79c6">.</span>svd(X, full_matrices<span style="color:#ff79c6">=</span><span style="color:#ff79c6">False</span>)
</span></span><span style="display:flex;"><span>        nuclear_norm <span style="color:#ff79c6">=</span> np<span style="color:#ff79c6">.</span>sum(s)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#6272a4"># Frobenius norm of observed entries</span>
</span></span><span style="display:flex;"><span>        mask <span style="color:#ff79c6">=</span> <span style="color:#ff79c6">~</span>np<span style="color:#ff79c6">.</span>isnan(A_observed)
</span></span><span style="display:flex;"><span>        frobenius_norm <span style="color:#ff79c6">=</span> np<span style="color:#ff79c6">.</span>sum((X[mask] <span style="color:#ff79c6">-</span> A_observed[mask])<span style="color:#ff79c6">**</span><span style="color:#bd93f9">2</span>)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#ff79c6">return</span> frobenius_norm <span style="color:#ff79c6">+</span> lambda_reg <span style="color:#ff79c6">*</span> nuclear_norm
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4"># Initialize with random matrix</span>
</span></span><span style="display:flex;"><span>    X_init <span style="color:#ff79c6">=</span> np<span style="color:#ff79c6">.</span>random<span style="color:#ff79c6">.</span>randn(<span style="color:#ff79c6">*</span>A_observed<span style="color:#ff79c6">.</span>shape)
</span></span><span style="display:flex;"><span>    X_init <span style="color:#ff79c6">=</span> X_init<span style="color:#ff79c6">.</span>flatten()
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4"># Optimize</span>
</span></span><span style="display:flex;"><span>    result <span style="color:#ff79c6">=</span> minimize(objective, X_init, method<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#39;L-BFGS-B&#39;</span>)
</span></span><span style="display:flex;"><span>    X_completed <span style="color:#ff79c6">=</span> result<span style="color:#ff79c6">.</span>x<span style="color:#ff79c6">.</span>reshape(A_observed<span style="color:#ff79c6">.</span>shape)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">return</span> X_completed
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">def</span> <span style="color:#50fa7b">impute_missing_data</span>(A, method<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#39;mean&#39;</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#f1fa8c">&#34;&#34;&#34;Impute missing data in adjacency matrix&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    A_imputed <span style="color:#ff79c6">=</span> A<span style="color:#ff79c6">.</span>copy()
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">if</span> method <span style="color:#ff79c6">==</span> <span style="color:#f1fa8c">&#39;mean&#39;</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#6272a4"># Mean imputation</span>
</span></span><span style="display:flex;"><span>        mean_val <span style="color:#ff79c6">=</span> np<span style="color:#ff79c6">.</span>nanmean(A)
</span></span><span style="display:flex;"><span>        A_imputed[np<span style="color:#ff79c6">.</span>isnan(A)] <span style="color:#ff79c6">=</span> mean_val
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">elif</span> method <span style="color:#ff79c6">==</span> <span style="color:#f1fa8c">&#39;regression&#39;</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#6272a4"># Regression imputation</span>
</span></span><span style="display:flex;"><span>        <span style="color:#ff79c6">for</span> j <span style="color:#ff79c6">in</span> <span style="color:#8be9fd;font-style:italic">range</span>(A<span style="color:#ff79c6">.</span>shape[<span style="color:#bd93f9">1</span>]):
</span></span><span style="display:flex;"><span>            missing_mask <span style="color:#ff79c6">=</span> np<span style="color:#ff79c6">.</span>isnan(A[:, j])
</span></span><span style="display:flex;"><span>            <span style="color:#ff79c6">if</span> np<span style="color:#ff79c6">.</span>any(missing_mask) <span style="color:#ff79c6">and</span> <span style="color:#ff79c6">not</span> np<span style="color:#ff79c6">.</span>all(missing_mask):
</span></span><span style="display:flex;"><span>                <span style="color:#6272a4"># Use other columns to predict missing values</span>
</span></span><span style="display:flex;"><span>                X <span style="color:#ff79c6">=</span> A[:, <span style="color:#ff79c6">~</span>missing_mask]
</span></span><span style="display:flex;"><span>                y <span style="color:#ff79c6">=</span> A[<span style="color:#ff79c6">~</span>missing_mask, j]
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>                <span style="color:#ff79c6">if</span> X<span style="color:#ff79c6">.</span>shape[<span style="color:#bd93f9">1</span>] <span style="color:#ff79c6">&gt;</span> <span style="color:#bd93f9">0</span>:
</span></span><span style="display:flex;"><span>                    <span style="color:#6272a4"># Simple linear regression</span>
</span></span><span style="display:flex;"><span>                    beta <span style="color:#ff79c6">=</span> np<span style="color:#ff79c6">.</span>linalg<span style="color:#ff79c6">.</span>lstsq(X, y, rcond<span style="color:#ff79c6">=</span><span style="color:#ff79c6">None</span>)[<span style="color:#bd93f9">0</span>]
</span></span><span style="display:flex;"><span>                    A_imputed[missing_mask, j] <span style="color:#ff79c6">=</span> X[missing_mask] <span style="color:#ff79c6">@</span> beta
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">elif</span> method <span style="color:#ff79c6">==</span> <span style="color:#f1fa8c">&#39;matrix_completion&#39;</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#6272a4"># Matrix completion</span>
</span></span><span style="display:flex;"><span>        A_imputed <span style="color:#ff79c6">=</span> matrix_completion(A)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">return</span> A_imputed
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">def</span> <span style="color:#50fa7b">evaluate_reconstruction</span>(G_original, G_reconstructed):
</span></span><span style="display:flex;"><span>    <span style="color:#f1fa8c">&#34;&#34;&#34;Evaluate network reconstruction quality&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    A_original <span style="color:#ff79c6">=</span> nx<span style="color:#ff79c6">.</span>adjacency_matrix(G_original)<span style="color:#ff79c6">.</span>toarray()
</span></span><span style="display:flex;"><span>    A_reconstructed <span style="color:#ff79c6">=</span> nx<span style="color:#ff79c6">.</span>adjacency_matrix(G_reconstructed)<span style="color:#ff79c6">.</span>toarray()
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4"># Edge accuracy</span>
</span></span><span style="display:flex;"><span>    edge_accuracy <span style="color:#ff79c6">=</span> np<span style="color:#ff79c6">.</span>mean(A_original <span style="color:#ff79c6">==</span> A_reconstructed)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4"># Precision and recall</span>
</span></span><span style="display:flex;"><span>    tp <span style="color:#ff79c6">=</span> np<span style="color:#ff79c6">.</span>sum((A_original <span style="color:#ff79c6">==</span> <span style="color:#bd93f9">1</span>) <span style="color:#ff79c6">&amp;</span> (A_reconstructed <span style="color:#ff79c6">==</span> <span style="color:#bd93f9">1</span>))
</span></span><span style="display:flex;"><span>    fp <span style="color:#ff79c6">=</span> np<span style="color:#ff79c6">.</span>sum((A_original <span style="color:#ff79c6">==</span> <span style="color:#bd93f9">0</span>) <span style="color:#ff79c6">&amp;</span> (A_reconstructed <span style="color:#ff79c6">==</span> <span style="color:#bd93f9">1</span>))
</span></span><span style="display:flex;"><span>    fn <span style="color:#ff79c6">=</span> np<span style="color:#ff79c6">.</span>sum((A_original <span style="color:#ff79c6">==</span> <span style="color:#bd93f9">1</span>) <span style="color:#ff79c6">&amp;</span> (A_reconstructed <span style="color:#ff79c6">==</span> <span style="color:#bd93f9">0</span>))
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    precision <span style="color:#ff79c6">=</span> tp <span style="color:#ff79c6">/</span> (tp <span style="color:#ff79c6">+</span> fp) <span style="color:#ff79c6">if</span> (tp <span style="color:#ff79c6">+</span> fp) <span style="color:#ff79c6">&gt;</span> <span style="color:#bd93f9">0</span> <span style="color:#ff79c6">else</span> <span style="color:#bd93f9">0</span>
</span></span><span style="display:flex;"><span>    recall <span style="color:#ff79c6">=</span> tp <span style="color:#ff79c6">/</span> (tp <span style="color:#ff79c6">+</span> fn) <span style="color:#ff79c6">if</span> (tp <span style="color:#ff79c6">+</span> fn) <span style="color:#ff79c6">&gt;</span> <span style="color:#bd93f9">0</span> <span style="color:#ff79c6">else</span> <span style="color:#bd93f9">0</span>
</span></span><span style="display:flex;"><span>    f1 <span style="color:#ff79c6">=</span> <span style="color:#bd93f9">2</span> <span style="color:#ff79c6">*</span> precision <span style="color:#ff79c6">*</span> recall <span style="color:#ff79c6">/</span> (precision <span style="color:#ff79c6">+</span> recall) <span style="color:#ff79c6">if</span> (precision <span style="color:#ff79c6">+</span> recall) <span style="color:#ff79c6">&gt;</span> <span style="color:#bd93f9">0</span> <span style="color:#ff79c6">else</span> <span style="color:#bd93f9">0</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4"># Structural similarity</span>
</span></span><span style="display:flex;"><span>    degree_correlation <span style="color:#ff79c6">=</span> np<span style="color:#ff79c6">.</span>corrcoef(
</span></span><span style="display:flex;"><span>        [G_original<span style="color:#ff79c6">.</span>degree(i) <span style="color:#ff79c6">for</span> i <span style="color:#ff79c6">in</span> G_original<span style="color:#ff79c6">.</span>nodes()],
</span></span><span style="display:flex;"><span>        [G_reconstructed<span style="color:#ff79c6">.</span>degree(i) <span style="color:#ff79c6">for</span> i <span style="color:#ff79c6">in</span> G_reconstructed<span style="color:#ff79c6">.</span>nodes()]
</span></span><span style="display:flex;"><span>    )[<span style="color:#bd93f9">0</span>, <span style="color:#bd93f9">1</span>]
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">return</span> {
</span></span><span style="display:flex;"><span>        <span style="color:#f1fa8c">&#39;edge_accuracy&#39;</span>: edge_accuracy,
</span></span><span style="display:flex;"><span>        <span style="color:#f1fa8c">&#39;precision&#39;</span>: precision,
</span></span><span style="display:flex;"><span>        <span style="color:#f1fa8c">&#39;recall&#39;</span>: recall,
</span></span><span style="display:flex;"><span>        <span style="color:#f1fa8c">&#39;f1&#39;</span>: f1,
</span></span><span style="display:flex;"><span>        <span style="color:#f1fa8c">&#39;degree_correlation&#39;</span>: degree_correlation
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">def</span> <span style="color:#50fa7b">plot_inference_results</span>(G_original, G_partial, G_reconstructed, 
</span></span><span style="display:flex;"><span>                          link_prediction_results, title<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;Network Inference&#34;</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#f1fa8c">&#34;&#34;&#34;Plot network inference results&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    fig, ((ax1, ax2), (ax3, ax4)) <span style="color:#ff79c6">=</span> plt<span style="color:#ff79c6">.</span>subplots(<span style="color:#bd93f9">2</span>, <span style="color:#bd93f9">2</span>, figsize<span style="color:#ff79c6">=</span>(<span style="color:#bd93f9">15</span>, <span style="color:#bd93f9">12</span>))
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4"># Original network</span>
</span></span><span style="display:flex;"><span>    pos <span style="color:#ff79c6">=</span> nx<span style="color:#ff79c6">.</span>spring_layout(G_original, k<span style="color:#ff79c6">=</span><span style="color:#bd93f9">1</span>, iterations<span style="color:#ff79c6">=</span><span style="color:#bd93f9">50</span>)
</span></span><span style="display:flex;"><span>    nx<span style="color:#ff79c6">.</span>draw(G_original, pos, ax<span style="color:#ff79c6">=</span>ax1, node_color<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#39;lightblue&#39;</span>, 
</span></span><span style="display:flex;"><span>            edge_color<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#39;gray&#39;</span>, alpha<span style="color:#ff79c6">=</span><span style="color:#bd93f9">0.6</span>, node_size<span style="color:#ff79c6">=</span><span style="color:#bd93f9">50</span>)
</span></span><span style="display:flex;"><span>    ax1<span style="color:#ff79c6">.</span>set_title(<span style="color:#f1fa8c">&#39;Original Network&#39;</span>)
</span></span><span style="display:flex;"><span>    ax1<span style="color:#ff79c6">.</span>axis(<span style="color:#f1fa8c">&#39;off&#39;</span>)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4"># Partial network</span>
</span></span><span style="display:flex;"><span>    nx<span style="color:#ff79c6">.</span>draw(G_partial, pos, ax<span style="color:#ff79c6">=</span>ax2, node_color<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#39;lightcoral&#39;</span>, 
</span></span><span style="display:flex;"><span>            edge_color<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#39;gray&#39;</span>, alpha<span style="color:#ff79c6">=</span><span style="color:#bd93f9">0.6</span>, node_size<span style="color:#ff79c6">=</span><span style="color:#bd93f9">50</span>)
</span></span><span style="display:flex;"><span>    ax2<span style="color:#ff79c6">.</span>set_title(<span style="color:#f1fa8c">&#39;Partial Network (Missing Edges)&#39;</span>)
</span></span><span style="display:flex;"><span>    ax2<span style="color:#ff79c6">.</span>axis(<span style="color:#f1fa8c">&#39;off&#39;</span>)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4"># Reconstructed network</span>
</span></span><span style="display:flex;"><span>    nx<span style="color:#ff79c6">.</span>draw(G_reconstructed, pos, ax<span style="color:#ff79c6">=</span>ax3, node_color<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#39;lightgreen&#39;</span>, 
</span></span><span style="display:flex;"><span>            edge_color<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#39;gray&#39;</span>, alpha<span style="color:#ff79c6">=</span><span style="color:#bd93f9">0.6</span>, node_size<span style="color:#ff79c6">=</span><span style="color:#bd93f9">50</span>)
</span></span><span style="display:flex;"><span>    ax3<span style="color:#ff79c6">.</span>set_title(<span style="color:#f1fa8c">&#39;Reconstructed Network&#39;</span>)
</span></span><span style="display:flex;"><span>    ax3<span style="color:#ff79c6">.</span>axis(<span style="color:#f1fa8c">&#39;off&#39;</span>)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4"># Link prediction ROC curve</span>
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">if</span> <span style="color:#f1fa8c">&#39;y_test&#39;</span> <span style="color:#ff79c6">in</span> link_prediction_results <span style="color:#ff79c6">and</span> <span style="color:#f1fa8c">&#39;y_pred_proba&#39;</span> <span style="color:#ff79c6">in</span> link_prediction_results:
</span></span><span style="display:flex;"><span>        <span style="color:#ff79c6">from</span> sklearn.metrics <span style="color:#ff79c6">import</span> roc_curve
</span></span><span style="display:flex;"><span>        fpr, tpr, _ <span style="color:#ff79c6">=</span> roc_curve(link_prediction_results[<span style="color:#f1fa8c">&#39;y_test&#39;</span>], 
</span></span><span style="display:flex;"><span>                               link_prediction_results[<span style="color:#f1fa8c">&#39;y_pred_proba&#39;</span>])
</span></span><span style="display:flex;"><span>        ax4<span style="color:#ff79c6">.</span>plot(fpr, tpr, <span style="color:#f1fa8c">&#39;b-&#39;</span>, linewidth<span style="color:#ff79c6">=</span><span style="color:#bd93f9">2</span>, label<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">f</span><span style="color:#f1fa8c">&#39;AUC = </span><span style="color:#f1fa8c">{</span>link_prediction_results[<span style="color:#f1fa8c">&#34;auc&#34;</span>]<span style="color:#f1fa8c">:</span><span style="color:#f1fa8c">.3f</span><span style="color:#f1fa8c">}</span><span style="color:#f1fa8c">&#39;</span>)
</span></span><span style="display:flex;"><span>        ax4<span style="color:#ff79c6">.</span>plot([<span style="color:#bd93f9">0</span>, <span style="color:#bd93f9">1</span>], [<span style="color:#bd93f9">0</span>, <span style="color:#bd93f9">1</span>], <span style="color:#f1fa8c">&#39;r--&#39;</span>, alpha<span style="color:#ff79c6">=</span><span style="color:#bd93f9">0.5</span>)
</span></span><span style="display:flex;"><span>        ax4<span style="color:#ff79c6">.</span>set_xlabel(<span style="color:#f1fa8c">&#39;False Positive Rate&#39;</span>)
</span></span><span style="display:flex;"><span>        ax4<span style="color:#ff79c6">.</span>set_ylabel(<span style="color:#f1fa8c">&#39;True Positive Rate&#39;</span>)
</span></span><span style="display:flex;"><span>        ax4<span style="color:#ff79c6">.</span>set_title(<span style="color:#f1fa8c">&#39;Link Prediction ROC Curve&#39;</span>)
</span></span><span style="display:flex;"><span>        ax4<span style="color:#ff79c6">.</span>legend()
</span></span><span style="display:flex;"><span>        ax4<span style="color:#ff79c6">.</span>grid(<span style="color:#ff79c6">True</span>, alpha<span style="color:#ff79c6">=</span><span style="color:#bd93f9">0.3</span>)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    plt<span style="color:#ff79c6">.</span>suptitle(title)
</span></span><span style="display:flex;"><span>    plt<span style="color:#ff79c6">.</span>tight_layout()
</span></span><span style="display:flex;"><span>    plt<span style="color:#ff79c6">.</span>show()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4"># Example: Network inference</span>
</span></span><span style="display:flex;"><span>G <span style="color:#ff79c6">=</span> nx<span style="color:#ff79c6">.</span>barabasi_albert_graph(<span style="color:#bd93f9">50</span>, <span style="color:#bd93f9">3</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4"># Generate partial network</span>
</span></span><span style="display:flex;"><span>G_partial, removed_edges <span style="color:#ff79c6">=</span> generate_partial_network(G, missing_fraction<span style="color:#ff79c6">=</span><span style="color:#bd93f9">0.3</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4"># Calculate similarity measures</span>
</span></span><span style="display:flex;"><span>similarities <span style="color:#ff79c6">=</span> calculate_similarity_measures(G_partial)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4"># Predict links</span>
</span></span><span style="display:flex;"><span>link_prediction_results <span style="color:#ff79c6">=</span> predict_links(G_partial, similarities, method<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#39;common_neighbors&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4"># Reconstruct network</span>
</span></span><span style="display:flex;"><span>A_partial <span style="color:#ff79c6">=</span> nx<span style="color:#ff79c6">.</span>adjacency_matrix(G_partial)<span style="color:#ff79c6">.</span>toarray()
</span></span><span style="display:flex;"><span>A_reconstructed <span style="color:#ff79c6">=</span> impute_missing_data(A_partial, method<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#39;matrix_completion&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4"># Create reconstructed network</span>
</span></span><span style="display:flex;"><span>G_reconstructed <span style="color:#ff79c6">=</span> nx<span style="color:#ff79c6">.</span>from_numpy_array(A_reconstructed)
</span></span><span style="display:flex;"><span>G_reconstructed <span style="color:#ff79c6">=</span> nx<span style="color:#ff79c6">.</span>Graph(G_reconstructed)  <span style="color:#6272a4"># Remove self-loops and parallel edges</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4"># Evaluate reconstruction</span>
</span></span><span style="display:flex;"><span>evaluation <span style="color:#ff79c6">=</span> evaluate_reconstruction(G, G_reconstructed)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8be9fd;font-style:italic">print</span>(<span style="color:#f1fa8c">&#34;Network Inference Results:&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#8be9fd;font-style:italic">print</span>(<span style="color:#f1fa8c">f</span><span style="color:#f1fa8c">&#34;Edge accuracy: </span><span style="color:#f1fa8c">{</span>evaluation[<span style="color:#f1fa8c">&#39;edge_accuracy&#39;</span>]<span style="color:#f1fa8c">:</span><span style="color:#f1fa8c">.3f</span><span style="color:#f1fa8c">}</span><span style="color:#f1fa8c">&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#8be9fd;font-style:italic">print</span>(<span style="color:#f1fa8c">f</span><span style="color:#f1fa8c">&#34;Precision: </span><span style="color:#f1fa8c">{</span>evaluation[<span style="color:#f1fa8c">&#39;precision&#39;</span>]<span style="color:#f1fa8c">:</span><span style="color:#f1fa8c">.3f</span><span style="color:#f1fa8c">}</span><span style="color:#f1fa8c">&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#8be9fd;font-style:italic">print</span>(<span style="color:#f1fa8c">f</span><span style="color:#f1fa8c">&#34;Recall: </span><span style="color:#f1fa8c">{</span>evaluation[<span style="color:#f1fa8c">&#39;recall&#39;</span>]<span style="color:#f1fa8c">:</span><span style="color:#f1fa8c">.3f</span><span style="color:#f1fa8c">}</span><span style="color:#f1fa8c">&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#8be9fd;font-style:italic">print</span>(<span style="color:#f1fa8c">f</span><span style="color:#f1fa8c">&#34;F1-score: </span><span style="color:#f1fa8c">{</span>evaluation[<span style="color:#f1fa8c">&#39;f1&#39;</span>]<span style="color:#f1fa8c">:</span><span style="color:#f1fa8c">.3f</span><span style="color:#f1fa8c">}</span><span style="color:#f1fa8c">&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#8be9fd;font-style:italic">print</span>(<span style="color:#f1fa8c">f</span><span style="color:#f1fa8c">&#34;Degree correlation: </span><span style="color:#f1fa8c">{</span>evaluation[<span style="color:#f1fa8c">&#39;degree_correlation&#39;</span>]<span style="color:#f1fa8c">:</span><span style="color:#f1fa8c">.3f</span><span style="color:#f1fa8c">}</span><span style="color:#f1fa8c">&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#8be9fd;font-style:italic">print</span>(<span style="color:#f1fa8c">f</span><span style="color:#f1fa8c">&#34;Link prediction AUC: </span><span style="color:#f1fa8c">{</span>link_prediction_results[<span style="color:#f1fa8c">&#39;auc&#39;</span>]<span style="color:#f1fa8c">:</span><span style="color:#f1fa8c">.3f</span><span style="color:#f1fa8c">}</span><span style="color:#f1fa8c">&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4"># Plot results</span>
</span></span><span style="display:flex;"><span>plot_inference_results(G, G_partial, G_reconstructed, link_prediction_results)
</span></span></code></pre></div><h2 id="key-takeaways">Key Takeaways<a hidden class="anchor" aria-hidden="true" href="#key-takeaways">#</a></h2>
<ol>
<li><strong>Statistical inference</strong>: Maximum likelihood and Bayesian methods for parameter estimation</li>
<li><strong>Link prediction</strong>: Various similarity measures for predicting missing edges</li>
<li><strong>Matrix completion</strong>: Nuclear norm minimization for network reconstruction</li>
<li><strong>Missing data</strong>: Different types and imputation methods</li>
<li><strong>Network tomography</strong>: Inferring topology from partial observations</li>
<li><strong>Applications</strong>: Important for materials science and defect networks</li>
<li><strong>Evaluation</strong>: Multiple metrics for assessing reconstruction quality</li>
</ol>
<h2 id="references">References<a hidden class="anchor" aria-hidden="true" href="#references">#</a></h2>
<ol>
<li>Newman, M. E. J. (2010). Networks: An Introduction. Oxford University Press.</li>
<li>Liben-Nowell, D., &amp; Kleinberg, J. (2007). The link-prediction problem for social networks. Journal of the American Society for Information Science and Technology, 58(7), 1019-1031.</li>
<li>Candès, E. J., &amp; Recht, B. (2009). Exact matrix completion via convex optimization. Foundations of Computational Mathematics, 9(6), 717-772.</li>
<li>Kipf, T. N., &amp; Welling, M. (2016). Semi-supervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907.</li>
</ol>
<hr>
<p><em>Network inference provides powerful tools for reconstructing network structure from partial data, with important applications in materials science and complex systems.</em></p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://Linlin-resh.github.io/tags/reading-notes/">Reading-Notes</a></li>
      <li><a href="https://Linlin-resh.github.io/tags/network-theory/">Network-Theory</a></li>
      <li><a href="https://Linlin-resh.github.io/tags/network-inference/">Network-Inference</a></li>
      <li><a href="https://Linlin-resh.github.io/tags/statistical-inference/">Statistical-Inference</a></li>
      <li><a href="https://Linlin-resh.github.io/tags/network-reconstruction/">Network-Reconstruction</a></li>
    </ul>

<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Reading Notes: Newman&#39;s Networks Chapter 12 - Network Inference on x"
            href="https://x.com/intent/tweet/?text=Reading%20Notes%3a%20Newman%27s%20Networks%20Chapter%2012%20-%20Network%20Inference&amp;url=https%3a%2f%2fLinlin-resh.github.io%2fposts%2freading-notes-newman-ch12%2f&amp;hashtags=reading-notes%2cnetwork-theory%2cnetwork-inference%2cstatistical-inference%2cnetwork-reconstruction">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Reading Notes: Newman&#39;s Networks Chapter 12 - Network Inference on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fLinlin-resh.github.io%2fposts%2freading-notes-newman-ch12%2f&amp;title=Reading%20Notes%3a%20Newman%27s%20Networks%20Chapter%2012%20-%20Network%20Inference&amp;summary=Reading%20Notes%3a%20Newman%27s%20Networks%20Chapter%2012%20-%20Network%20Inference&amp;source=https%3a%2f%2fLinlin-resh.github.io%2fposts%2freading-notes-newman-ch12%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Reading Notes: Newman&#39;s Networks Chapter 12 - Network Inference on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2fLinlin-resh.github.io%2fposts%2freading-notes-newman-ch12%2f&title=Reading%20Notes%3a%20Newman%27s%20Networks%20Chapter%2012%20-%20Network%20Inference">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Reading Notes: Newman&#39;s Networks Chapter 12 - Network Inference on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fLinlin-resh.github.io%2fposts%2freading-notes-newman-ch12%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Reading Notes: Newman&#39;s Networks Chapter 12 - Network Inference on whatsapp"
            href="https://api.whatsapp.com/send?text=Reading%20Notes%3a%20Newman%27s%20Networks%20Chapter%2012%20-%20Network%20Inference%20-%20https%3a%2f%2fLinlin-resh.github.io%2fposts%2freading-notes-newman-ch12%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Reading Notes: Newman&#39;s Networks Chapter 12 - Network Inference on telegram"
            href="https://telegram.me/share/url?text=Reading%20Notes%3a%20Newman%27s%20Networks%20Chapter%2012%20-%20Network%20Inference&amp;url=https%3a%2f%2fLinlin-resh.github.io%2fposts%2freading-notes-newman-ch12%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Reading Notes: Newman&#39;s Networks Chapter 12 - Network Inference on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=Reading%20Notes%3a%20Newman%27s%20Networks%20Chapter%2012%20-%20Network%20Inference&u=https%3a%2f%2fLinlin-resh.github.io%2fposts%2freading-notes-newman-ch12%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://Linlin-resh.github.io/">Notes on AI4Science &amp; Graph Theory</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
